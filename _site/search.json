[
  {
    "objectID": "cheat_sheet/cheat_sheet.html",
    "href": "cheat_sheet/cheat_sheet.html",
    "title": "Basic R coding overview",
    "section": "",
    "text": "This document aligns with the Stata cheat sheet."
  },
  {
    "objectID": "cheat_sheet/cheat_sheet.html#create-and-execute-an-r-script",
    "href": "cheat_sheet/cheat_sheet.html#create-and-execute-an-r-script",
    "title": "Basic R coding overview",
    "section": "2.1 Create and execute an R script",
    "text": "2.1 Create and execute an R script\nIn RStudio, you can run R code directly in the console. This is helpful for running quick one-off code. To save your code, write it as an .R script, which allows one to run the same commands in the future to reproduce your work. To open a new .R script, one can:\n\nClick on the “New File” icon in the top left of RStudio, then select “R Script”.\nFile -&gt; New File -&gt; R Script"
  },
  {
    "objectID": "cheat_sheet/cheat_sheet.html#read-in-a-dataset-.rds-.dta-.xlsx-.csv-.sas7bdat",
    "href": "cheat_sheet/cheat_sheet.html#read-in-a-dataset-.rds-.dta-.xlsx-.csv-.sas7bdat",
    "title": "Basic R coding overview",
    "section": "2.2 Read in a Dataset (.rds, .dta, .xlsx, .csv, .sas7bdat)",
    "text": "2.2 Read in a Dataset (.rds, .dta, .xlsx, .csv, .sas7bdat)\nDatasets can be in various formats, such as .rds (R), .dta (Stata), .xlsx (Excel), .csv (Comma Separated Value), and .sas7bdat (SAS) files. Some of these datasets require additional packages to download into R. To install a package, run:\n\ninstall.packages(\"package_name\")\n\nWhen a function belongs to a package, you can use that function by running package_name::function_name() or by running library(package_name) at some point before function_name().\nYou will need to include the path to the dataset file in your code. To determine the location of a dataset stored on a Windows computer, you can right-click and click on ‘Properties’ and copy and paste the location path. On a Mac, right-click the file, then press Option so that “Copy filename as Pathname” appears in the menu.\nUnlike Stata, you can have multiple datasets open in the same R session. When reading in a dataset, you must store it as an object so that you can refer to it later. This is done in R using the “assignment arrow” &lt;-.\nReading in datasets can also be done from File -&gt; Import Dataset. This will bring up a window with options that will help you write the code that can be saved in an R script to use again.\n\n2.2.1 Reading an R .rds file\nThe readRDS() function is part of “base R” so does not need a separate package. The {readr} package includes many functions for reading in data that do the same things as the base R packages, often with better defaults.\n\ndataset &lt;- readRDS(\"filepath/filename.rds\")\n\nor\n\ndataset &lt;- readr::read_rds(\"filepath/filename.rds\")\n\n\n\n2.2.2 Reading a Stata .dta file\n\ndataset &lt;- haven::read_stata(\"filepath/filename.dta\")\n\n\n\n2.2.3 Importing an Excel file\nBecause data in Excel can take many different forms (different sheets, extra rows with information, etc.), there are many arguments to this function to make sure you are reading in the right data. It will default to the first sheet, with the first row used as column names.\n\ndataset &lt;- readxl::read_excel(\"filepath/filename.xlsx\")\n\n\n\n2.2.4 Importing a .csv file\n\ndataset &lt;- read.csv(\"filepath/filename.csv\")\n\nor\n\ndataset &lt;- readr::read_csv(\"filepath/filename.csv\")\n\n\n\n2.2.5 Reading in a SAS file\n\nhaven::read_sas(\"filepath/filename.sas7bdat\",\n                \"filepath/catalog.sas7bcat\")"
  },
  {
    "objectID": "cheat_sheet/cheat_sheet.html#get-to-know-your-data",
    "href": "cheat_sheet/cheat_sheet.html#get-to-know-your-data",
    "title": "Basic R coding overview",
    "section": "2.3 Get to know your data",
    "text": "2.3 Get to know your data\nThere are a number of ways to summarize your dataset. The summary() function will print summary statistics for each variable.\n\nsummary(dataset)\n\nThe glimpse() function tells you the number of rows and columns, what type of variable each column contains, and shows you the first few observations.\n\ndplyr::glimpse(dataset)\n\nTo see what the entire dataset looks like, you can click on the name of the dataset in the Environment pane. This will open up a new tab with the dataset. You can also bring up this tab with:\n\nView(dataset)\n\nor\n\ntibble::view(dataset)\n\nTo compactly list the variable names:\n\nnames(dataset)\n\nTo count the number of observations (i.e. rows of data) in a dataset:\n\nnrow(dataset)\n\nTo count the number of observations in a subset of the data:\nCode for character variables:\n\nnrow(dataset[dataset$varname == \"Male\",])\n\nCode for numeric variables:\n\nnrow(dataset[dataset$varname == 1,])\n\nYou can also count the number of observations for each value of varname with:\n\ndplyr::count(dataset, varname)"
  },
  {
    "objectID": "cheat_sheet/cheat_sheet.html#generate-quadratic-term",
    "href": "cheat_sheet/cheat_sheet.html#generate-quadratic-term",
    "title": "Basic R coding overview",
    "section": "3.1 Generate quadratic term",
    "text": "3.1 Generate quadratic term\n\ndataset$newvar &lt;- dataset$oldvar * dataset$newvar\n\nor\n\ndataset &lt;- mutate(dataset, newvar = oldvar * oldvar)\n\nYou can also create a quadratic term directly in a model itself, bit it must be wrapped in I(): var + I(var^2) + other_vars ."
  },
  {
    "objectID": "cheat_sheet/cheat_sheet.html#generate-a-categorical-variable-based-on-cut-points",
    "href": "cheat_sheet/cheat_sheet.html#generate-a-categorical-variable-based-on-cut-points",
    "title": "Basic R coding overview",
    "section": "3.2 Generate a categorical variable based on cut-points",
    "text": "3.2 Generate a categorical variable based on cut-points\nThere are a couple ways to create a categorical variable 'newvar' based on cutpoint values of 'oldvar' at cutpoints x and y.\n\nOne can use the cut() function to create a new categorical variable with cutpoints at the breaks = values. For example, say you have a variable with a minimum of 0 and a maximum of 100 with some missing values and you would like to make three categories defined by the values (0,x] (category 1), (x,y] (category 2), and (y,100] (category 3). For the breaks =argument, you will want to supply the left- hand breaks: a value lower than the minimum, x, y and then a value larger than the maximum. (You can use -Inf and Inf if you don’t know what the minimum and maximum are.) You can also use the include.lowest = and the right = arguments to change how the intervals are created.\n\ndataset$newvar &lt;- cut(dataset$newvar, \n                      breaks = c(-Inf, x, y, Inf))\n\nYou can also use case_when() if you want to be more explicit. For example, to generate a new categorical variable based on a set of cutpoints (ex. 40, 60, 80):\n\nlibrary(dplyr)\ndataset &lt;- mutate(dataset, newvar = case_when(\n  oldvar &lt; 40 ~ 0,\n  oldvar &gt;= 40 & oldvar &lt; 60 ~ 1,\n  oldvar &gt;= 60 & oldvar &lt; 80 ~ 2,\n  oldvar &gt;= 80 ~ 3\n))\n\nValues of oldvar that don’t meet any of the conditions will be assigned NA."
  },
  {
    "objectID": "cheat_sheet/cheat_sheet.html#generate-quantiles",
    "href": "cheat_sheet/cheat_sheet.html#generate-quantiles",
    "title": "Basic R coding overview",
    "section": "3.3 Generate quantiles",
    "text": "3.3 Generate quantiles\nUse the quantile() function to generate a categorical variable based on quantile cutoffs. In the code below, set the number of desired quantiles (here, tertiles) by changing the value of nquantiles.\n\nnquantiles &lt;- 3\ndataset$newvar &lt;- cut(dataset$oldvar, \n                      breaks = quantile(dataset$oldvar, \n                                        probs = seq(0, 1, \n                                                    length.out = nquantiles + 1)), \n                      include.lowest=TRUE)"
  },
  {
    "objectID": "cheat_sheet/cheat_sheet.html#generate-an-indicatordummy-variable",
    "href": "cheat_sheet/cheat_sheet.html#generate-an-indicatordummy-variable",
    "title": "Basic R coding overview",
    "section": "3.4 Generate an indicator/dummy variable",
    "text": "3.4 Generate an indicator/dummy variable\n\nYou generally don’t need to create indicator/dummy variables. In models, R will treat any factor variable as a series of indicator variables. If varname has numeric values, turn it into a factor variable (see next section):\n\n\ndataset$varname &lt;- factor(dataset$varname)\n\nand then use varname directly in a model. 2) One could also code the indicator/dummy variables manually using case_when(). 3) In some scenarios, it may be helpful to generate the indicator variables used in a model with:\n\nnewvars &lt;- as.data.frame(model.matrix(~varname + othervar, \n                                      data = dataset))\n\nNote that this will also create an intercept (a column of ones) and will also only contain the variables varname and othervar, not any others in the dataset."
  },
  {
    "objectID": "cheat_sheet/cheat_sheet.html#label-a-categorical-variable",
    "href": "cheat_sheet/cheat_sheet.html#label-a-categorical-variable",
    "title": "Basic R coding overview",
    "section": "3.5 Label a categorical variable",
    "text": "3.5 Label a categorical variable\nTo create a factor (categorical) variable, use the factor() function, with arguments levels = for the unique values and labels = for the names of those values. For example, if oldvar has values 0, 1, and 2, which should be named “small”, “medium”, “large”:\n\ndataset$newvar &lt;- factor(dataset$oldvar, levels = c(0, 1, 2), \n                         labels = c(\"small\", \"medium\", \"large\"))\n\nThe reference level is always the first level (above, “small”). In models, R will treat character variables as factor variables, and the levels will be in alphabetical order. For example, if the variable in the example above was already labeled, but not a factor variable, putting it in a model or using the factor() function would result in levels “large”, “medium”, and “small” (“large” being the reference”).\nTo determine whether a variable is already a factor variable, or whether it is a character variable (or another type), use:\n\nclass(dataset$varname)\n\nTo see the levels in order of a factor variable, use:\n\nlevels(dataset$varname)\n\nThe {forcats} package is designed to make working with categorical variables easier. If a variable has levels “large”, “medium”, and “small” and you want to change the order, you can use:\n\ndataset$newvar &lt;- forcats::fct_relevel(dataset$oldvar, \n                                       \"small\", \"medium\", \"large\"))\n\nTo rename the levels “sm”, “md”, and “lg”:\n\ndataset &lt;- forcats::fct_recode(dataset$oldvar, \n                               \"sm\" = \"small\", \"md\" = \"medium\", \"lg\" = \"large\"))\n\nIf the variable is numeric, you need to turn it into a character or factor variable before using fct_recode():\n\ndataset &lt;- forcats::fct_recode(as.character(dataset$oldvar), \n                               \"sm\" = \"0\", \"md\" = \"1\", \"lg\" = \"2\"))"
  },
  {
    "objectID": "cheat_sheet/cheat_sheet.html#sort-the-data",
    "href": "cheat_sheet/cheat_sheet.html#sort-the-data",
    "title": "Basic R coding overview",
    "section": "3.6 Sort the data",
    "text": "3.6 Sort the data\nThe default of the arrange() function from the {dplyr} package is in ascending order.\n\ndataset &lt;- dplyr::arrange(dataset, varname)\n\nTo sort in descending order:\n\nlibrary(dplyr)\ndataset &lt;- arrange(dataset, desc(varname))\n\nYou can sort on multiple variables to arrange observations in to ascending order based on varname1, and within each varname1 category one can sort into descending order by varname2.\n\nlibrary(dplyr)\ndataset &lt;- arrange(nlsy, varname1, desc(varname2))"
  },
  {
    "objectID": "cheat_sheet/cheat_sheet.html#merge-two-datasets",
    "href": "cheat_sheet/cheat_sheet.html#merge-two-datasets",
    "title": "Basic R coding overview",
    "section": "3.7 Merge two datasets",
    "text": "3.7 Merge two datasets\nTo merge two datasets, use a _join() function from the {dplyr} package: left_join(), right_join(), full_join(). The functions differ by how they treat rows without a match in the “left-hand side” dataset and the “right-hand side” dataset. This will keep all observations in dataset1 and merge with only observations in dataset2 with a matching id:\n\nlibrary(dplyr)\ndataset3 &lt;- left_join(dataset1, dataset2, join_by(id))"
  },
  {
    "objectID": "cheat_sheet/cheat_sheet.html#keeping-and-dropping-observations",
    "href": "cheat_sheet/cheat_sheet.html#keeping-and-dropping-observations",
    "title": "Basic R coding overview",
    "section": "3.8 Keeping and dropping observations",
    "text": "3.8 Keeping and dropping observations\nTo create a dataset that is a subset of another dataset, use filter(). This code will retain all observations with both the age and sex requirement:\n\ndataset2 &lt;- dplyr::filter(dataset1, age &gt; 35, sex == \"F\")\n\nYou can also explictly use logic like & and | (or). To retain observations that are either over 35 or female:\n\ndataset2 &lt;- dplyr::filter(dataset1, age &gt; 35 | sex == \"F\")"
  },
  {
    "objectID": "cheat_sheet/cheat_sheet.html#categorical-data-frequencies-tests-and-association-measures",
    "href": "cheat_sheet/cheat_sheet.html#categorical-data-frequencies-tests-and-association-measures",
    "title": "Basic R coding overview",
    "section": "4.1 Categorical data: frequencies, tests, and association measures",
    "text": "4.1 Categorical data: frequencies, tests, and association measures\n\n4.1.1 One-way frequency table\nOne can get a frequency table using the count() function.\n\ndplyr::count(dataset, varname)\n\nThe tabyl() function from the {janitor} package is also helpful for frequency tables because it will also add percentages by default to a one-way frequency table.\n\njanitor::tabyl(dataset, varname)\n\nFor a binary variable, you can use prop.test() or binom.test() (exact intervals) to get confidence intervals for the proportion of 1’s (or the “higher” level for a factor variable):\n\nprop.test(table(dataset$binary_var))\n\n\n\n4.1.2 RxC frequency tables\nOne can easily extend the functions above to cross-tabulate two categorical variables.\n\ndplyr::count(dataset, varname1, varname2)\njanitor::tabyl(dataset, varname1, varname2)\n\nTo get proportions when using tabyl():\n\nlibrary(janitor)\ntabyl(dataset, varname1, varname2) |&gt; adorn_percentages()\n\n\n\n4.1.3 Two-sample test of proportions\nTo compare proportions of varname2 stratified by varname1 and get a confidence interval for the difference in proportions;\n\nprop.test(table(dataset$varname1, dataset$varname2))\n\n\n\n4.1.4 Estimate measures of association\nThe {epitools} package contains a functions for estimating many simple epidemiologic quantities. For example, to estiamte a risk ratio (and the corresponding proportions):\n\nepitools::epitab(dataset$exposure, dataset$outcome, \n                 method = \"riskratio\")\n\n\n\n4.1.5 Stratified frequency tables\nYou can estimate any summary statistics of a variable (ex. varname1 or varname2) within each value of a categorical variable (ex. categoricalvariable):\n\ndplyr::summarize(dataset, mean_1 = mean(varname1), \n                 sd_2 = sd(varname2), .by = categoricalvariable)\n\nFor two-way frequency tables (varname1 x varname2) stratified by a third variable (categoricalvariable):\n\njanitor::tabyl(dataset, varname1, varname2, categoricalvariable)"
  },
  {
    "objectID": "cheat_sheet/cheat_sheet.html#continuous-data-summary-statistics-visualization-and-statistical-tests",
    "href": "cheat_sheet/cheat_sheet.html#continuous-data-summary-statistics-visualization-and-statistical-tests",
    "title": "Basic R coding overview",
    "section": "4.2 Continuous data: summary statistics, visualization, and statistical tests",
    "text": "4.2 Continuous data: summary statistics, visualization, and statistical tests\n\n4.2.1 Measures of location and variance\nUse the summary command to obtain summary statistics for continuous data (mean, minimum, maximum, median, IQR):\n\nsummary(dataset$varname)\n\nYou can also estimate arbitraty sumamry statistics using dplyr::summarize():\n\ndplyr::summarize(dataset, mean = mean(varname), sd = sd(varname))\n\nOne can estimate the standard errors and 95% CI of the mean using the ci or ci means command.t.test() function:\n\nt.test(dataset$varname)\n\n\n\n4.2.2 Histogram\nA histogram graphic for continuous data:\n\nhist(dataset$age)\n\nWith the {ggplot2} package:\n\nggplot(dataset, aes(x = age)) + \n    geom_histogram() +\n    labs(title = \"Histogram of age\", \n         x = \"Age\")\n\n\n\n4.2.3 Box plots\nTo show a box-and-whisker plot of age and a box plot of age by a categorical variable (ex. sex):\n\nboxplot(dataset$age, dataset$sex)\n\n\nggplot(dataset, aes(y = age, x = sex)) + \n    geom_boxplot() +\n    labs(title = \"Boxplot of age by sex\", \n         x = \"Sex\", y = \"Age\")\n\n\n\n4.2.4 Scatterplot\nScatterplot of two continuous variables:\n\nplot(dataset$age, dataset$bmi)\n\n\nggplot(dataset, aes(y = age, x = bmi)) + \n    geom_point() +\n    labs(x = \"Age\", y = \"BMI\")\n\n\n\n4.2.5 Statistical Tests\nTo conduct a two-sample T-test (continuous variable by a binary variable), use the t.test() function with the var.equal = FALSE argument if desired:\n\nt.test(continuousvar ~ categoricalvar, \n       data = dataset, var.equal = FALSE)\n\nTo conduct a one-way ANOVA (test differences of two or more means), use the aov() function:\n\naov(continuousvar ~ categoricalvar, data = dataset)\n\nTo conduct a non-parametric test Wilcoxon Rank-sum test (aka Mann-Whitney U test), use the wilcox.test() function:\n\nwilcox.test(continuousvar ~ categoricalvar, data = dataset)\n\n\n\n4.2.6 Correlation coefficients\nOne can estimate correlation coefficients using the cor() function. The default is Pearson, one can estimate the Spearman correlation coefficients using the method = \"spearman\" argument:\n\ncor(dataset[, c(\"varname1\", \"varname2\", \"varname3\")], \n    method = \"spearman\")\n\nYou can also provide two vectors if a single correlation is desired. For confidence intervals and hypothesis tests, use cor.test().\n\ncor.test(dataset$varname1, dataset$varname2)"
  },
  {
    "objectID": "cheat_sheet/cheat_sheet.html#logistic-regression",
    "href": "cheat_sheet/cheat_sheet.html#logistic-regression",
    "title": "Basic R coding overview",
    "section": "5.1 Logistic Regression",
    "text": "5.1 Logistic Regression\n\n5.1.1 Using continuous or binary variables\nFit a logistic regression model:\n\nmodel &lt;- glm(outcome ~ exposure + var1 + var2, \n             data = dataset, family = binomial())\n\nCode to output the beta coefficients:\n\ncoef(model)\n\nCode to output the odds ratios:\n\nexp(coef(model))\n\nCoefficients, standard errors, p-values:\n\nsummary(model)\n\nCOnfidence intervals:\n\nconfint(model)\n\nThe {broom} package is helpful for getting model output:\n\nbroom::tidy(model, exponentiate = TRUE, conf.int = TRUE)\n\n\n\n5.1.2 Using indicator variables\nR automatically creates indicator variables for factor or character variables (see previous section). To force it to create indicator variables for a numeric variable, you can use factor():\n\nmodel &lt;- glm(outcome ~ exposure + factor(var1) + var2, \n             data = dataset, family = binomial())\n\nTo change the referent group, you can use fct_relevel() to move a new level to be the first level (the other levels will stay in their original order, unless you include them):\n\ndataset$newvar &lt;- forcats::fct_relevel(dataset$oldvar, \"ref\"))\nmodel &lt;- glm(outcome ~ exposure + newvar, \n             data = dataset, family = binomial())\n\n\n\n5.1.3 Stratified Logistic Regression\nTo fit a logistic regression model within levels of categoricalvar:\n\nlibrary(dplyr)\nmodels &lt;- dataset |&gt; \n  group_by(categoricalvar) |&gt; \n  group_map(~glm(outcome ~ exposure, data = .x))"
  },
  {
    "objectID": "cheat_sheet/cheat_sheet.html#linear-regression",
    "href": "cheat_sheet/cheat_sheet.html#linear-regression",
    "title": "Basic R coding overview",
    "section": "5.2 Linear Regression",
    "text": "5.2 Linear Regression\nOne can conduct a linear regression model using either the lm() function or the glm() function with family = gaussian(). All of the same functions work on these models to extract model output.\n\nmodel &lt;- lm(outcome ~ exposure + var1 + var1)\nbroom::tidy(model, conf.int = TRUE)"
  },
  {
    "objectID": "cheat_sheet/cheat_sheet.html#survival-data",
    "href": "cheat_sheet/cheat_sheet.html#survival-data",
    "title": "Basic R coding overview",
    "section": "5.3 Survival Data",
    "text": "5.3 Survival Data\n\n5.3.1 Set-up\nThe {survival} package is used for this entire section.\n\nlibrary(survival)\n\nWithin that package, the Surv() function is used to “create” the outcome and is used in other functions:\n\nSurv(timetooutcome, outcome)\n\n\n\n5.3.2 Graphs\nKaplan-Meier curves overall:\n\nkm &lt;- survfit(Surv(timetooutcome, outcome) ~ 1, \n              data = dataset)\nplot(km)\n\nKM curves by exposure groups:\n\nkm &lt;- survfit(Surv(timetooutcome, outcome) ~ exposure, \n              data = dataset)\nplot(km)\n\nTo add 95% confidence intervals and censoring marks to the figure:\n\nplot(km, conf.int = TRUE, mark.time = TRUE)\n\nLog negative-log survivor plots:\n\nplot(km, fun = \"cloglog\")\n\nThe {survminer} package is useful for creating survival curves for publication and can also include risk tables:\n\nsurvminer::ggsurvplot(km, risk.table = TRUE)\n\n\n\n5.3.3 Summary statistics\nTo see survivor function at various time points (ex. 30, 60, 90 days):\n\nsummary(km, times = c(30, 60, 90))\n\nYou can also use the tidy() function to extract the estimates and confidence intervals over all times in a nicer format:\n\nbroom::tidy(km)\n\nTo get median and other percentile survival times with confidence intervals:\n\nquantile(km, probs = c(0.25, 0.5, 0.75))\n\n\n\n5.3.4 Statistical tests\nLog-rank test:\n\nsurvdiff(Surv(timetooutcome, outcome) ~ exposure, \n         data = dataset)\n\nSee the {survminer} vignette for details on plotting survival curves with p-values from weighted log-rank tests (here, Tarone-Ware):\n\nsurvmire::ggsurvplot(km, data = dataset, \n                     pval = TRUE, pval.method = TRUE,\n                     log.rank.weights = \"sqrtN\",\n                     pval.method.coord = c(3, 0.1),\n                     pval.method.size = 4)\n\n\n\n5.3.5 Cox Regression\nOne can conduct a Cox regression model using the coxph() function from the {survival} package.\n\ncox &lt;- coxph(Surv(timetooutcome, outcome) ~ exposure, \n             data = dataset)\n\nThe functions from the logistic regression section can be used to extract model output.\nCompeting Risk Analysis: In carrying out a competing risk analysis, the “outcome” variable can take on three values. There must be a value for the actual event of interest (outcome=1); a value for censoring (outcome=0); and a value for the competing risk event (outcome=2).\n\nfg_data &lt;- finegray(Surv(timetooutcome, outcome) ~ exposure, \n                    data = dataset)\nfg_model &lt;- coxph(Surv(fgstart, fgstop, fgstatus) ~ exposure, \n                  weight = fgwt, data = fg_data)"
  },
  {
    "objectID": "cheat_sheet/cheat_sheet.html#goodness-of-fit-statistics",
    "href": "cheat_sheet/cheat_sheet.html#goodness-of-fit-statistics",
    "title": "Basic R coding overview",
    "section": "5.4 Goodness of Fit Statistics",
    "text": "5.4 Goodness of Fit Statistics\nTo get log Likelihood/AIC/BIC for most recent regression model:\n\nloglik(model)\nAIC(model)\nBIC(model)\n\nTo run a likelihood ratio test comparing two nested models:\n\nlmtest::lrtest(mod_full, mod_nested)"
  },
  {
    "objectID": "cheat_sheet/STATACheatSheet.html",
    "href": "cheat_sheet/STATACheatSheet.html",
    "title": "Basic Stata Coding Overview",
    "section": "",
    "text": "There is a lot of documentation and support available at your fingertips both within Stata and outside of Stata on blogs, other educational websites, YouTube and more.\n\nWithin Stata, use the help command to get an overview, more options and examples for a specific command. There is also the search command where you can type in key words and Stata will search for these key words.\n\n\nhelp(command_name)\nhelp command_name\nsearch [keyword search terms here]\n\nWithin the Stata Help menu, you can select ‘PDF Documentation’ to access the manuals.\nThere are also plenty of resources on the Stata Support site: http://www.Stata.com/support/\n\nStata is case sensitive (e.g. if a variable is ‘ID’, you must refer to it as ‘ID’, not ‘id’). ? It is best to save and write your Stata code in a .do file.\nNotes/comments can be added for easy annotation of the program. An asterisk at the beginning of the line denotes a comment that can be used interactively. For example:\n*This is a note that\n*Stata will not read\nWhen coding in Stata, Stata does not like to read in location paths or datasets that have a space in the name (e.g. Stata does not like to read in \"Your path here/name of dataset.dta\", and would prefer a file name without spaces, such as: \"Your_path_here/name_of_dataset.dta\").\nIf you only want to run a command for a subset of the data, add if varname==value to the end of the command statement (e.g. summarize age, if gender==1).\nIf you start to run a command and need to stop the command or prevent more output from appearing, you can select the Break icon in the top-right corner to stop the command.\nIn Stata 14 and older versions, while executing a command, Stata will display --more-- and pause until any key is pressed. To turn off the more message, use the command set more off. To turn the message on: set more on. From Stata 15, set more off is now the default option (help whatsnew14to15 =&gt; 71. Set more off now the default)"
  },
  {
    "objectID": "cheat_sheet/STATACheatSheet.html#create-and-execute-a-.do-file",
    "href": "cheat_sheet/STATACheatSheet.html#create-and-execute-a-.do-file",
    "title": "Basic Stata Coding Overview",
    "section": "2.1 Create and execute a .do file",
    "text": "2.1 Create and execute a .do file\nA do-file is a file containing a list of commands that can be saved, which allows one to run the same commands in the future to reproduce your work. To open a new .do file, one can:\n\nClick on the “Do-file Editor” icon located at the top Stata bar:\nOr, go to the menu options: File/New/Do-file, or Window/Do-file Editor/New Do-file Editor. A .do file will open:\n\nThe Do-File Editor acts just like Word or any text editor so that we can type any Stata commands.\nNote that do-file editor has different text colors for specific parts of the Stata commands:\n\nGreen: Comments (green arrow)\nRed: Character (ex. \"filename\", red arrow)\nBlue: Stata commands (ex. use, clear, summarize, histogram, graph, tabulate, regress, blue arrow)\nBlack: Other aspects of the command (black arrow)\n\nAdditional colors are added to other aspects of the commands. For example, if a command is misspelled (tablate rather than tabulate), this will not turn blue in the Do-File Editor and you can easily identify the spelling error.\nTo run all or a subset of the commands in the Do-File Editor, we can push the button at the top of the Do-File Editor that is labeled “Execute (Do)” if you hover over it (orange arrow). If you click this button, all of the commands in the do file will be executed. If you would like to execute only a subset of the commands, you can highlight the commands you would like to execute and then click the button.\nTo learn even more details about .do files (ex. more ways to write comments, long lines, error handling, logging the output, preventing -more- conditions, calling other do-files, creating and running do-files for Mac/Windows/Unix, or suppressing output), go the Stata manual (see Table 1)."
  },
  {
    "objectID": "cheat_sheet/STATACheatSheet.html#read-in-a-dataset-.dta-.xlsx-.csv-and-.xpt",
    "href": "cheat_sheet/STATACheatSheet.html#read-in-a-dataset-.dta-.xlsx-.csv-and-.xpt",
    "title": "Basic Stata Coding Overview",
    "section": "2.2 Read in a Dataset (.dta, .xlsx, .csv, and .xpt)",
    "text": "2.2 Read in a Dataset (.dta, .xlsx, .csv, and .xpt)\nDatasets can be in various formats, such as .dta (Stata), .xls (Excel), .csv (Comma Separated Value), and .sas7bdat (SAS) files. There are a few ways to read in these types of dataset files, some of which require you to know the location of the dataset on your computer. To determine the location of a dataset stored on a Windows computer, can right-click and click on ‘Properties’ and copy and paste the location path.\nThe option , clear will clear out a dataset if one is already open. If a dataset is open and you do not use the clear option and, you will get an error. If you need help or would like to learn more options, you can use the Stata help command by typing in help nameofcommandhere; for example, help use or help import or help insheet. Helpful video link: https://www.youtube.com/watch?v=3CjXMC2hFEA\nAnother option is to use the Stat/Transfer software to convert dataset from various formats into an .dta (Stata) file. Stat/Transfer is available within the HSPH student’s Virtual Desktop Infrastructure (VDI) system https://www.hsph.harvard.edu/information-technology/service/virtual-desktop-infrastructure/ https://www.hsph.harvard.edu/information-technology/frequently-asked-questions/vdifaq/student-vdi-software-inventory/\n\n2.2.1 Reading a Stata .dta file\n1) Use the use command followed by the data location in quotations. The option , clear will clear out a dataset if one is already open. If a dataset is open and you do not use the ‘clear’ option and, you will get an error.\nuse \"Yourpathhere/folder/nameofdataset.dta\", clear\nOr, 2) tell Stata the name of your working directory using the ‘cd’ command and then use the ‘use’ command to open the .dta file:\ncd \"Yourpathhere/folder\"\nuse nameofdataset, clear\nOr, 3) Use the drop-down menu: File/Open/ and then Browse for the Stata .dta file.\n\n\n2.2.2 Importing an Excel file\nThe data should be on the first Excel sheet tab. Use the import command to import an Excel file. The option , firstrow will tell Stata to treat the first row of Excel data as variable names. Alternatively, you can use the drop-down menu: File/Import/Excel Spreadsheet/ and browse for the Excel file and select the ‘Import first row as variable names’ option.\nimport excel Yourpathhere/nameofdataset.xlsx, firstrow\n\n\n2.2.3 Importing a .csv file\nUse the insheet command to import a .csv file.\ninsheet using \"Yourpathhere/nameofdataset.csv\", clear\n\n\n2.2.4 Reading in a SAS file\nCompared to Excel files, it is not as simple to read in a SAS file to Stata. Stata can easily import a SAS XPORT (*.xpt) file using the drop-down menu: File/Import/SAS XPORT and Browse for the .xpt file. Or you can use the import command below.\nimport sasxport \"Yourpathhere/nameofdataset.xpt\", clear\nIf you have SAS, you can use the proc export command in SAS to output a .dta file or an Excel file.\nIf you do not have SAS, then you may need to use the Stat/Transfer software that easily converts a SAS file to a Stata file. Stat/Transfer is available within the HSPH student’s Virtual Desktop Infrastructure (VDI) system:\n\nhttps://www.hsph.harvard.edu/information-technology/service/virtual-desktop-infrastructure/\nhttps://www.hsph.harvard.edu/information-technology/frequently-asked-questions/vdi-faq/studentvdi-software-inventory/\n\nHelpful link: https://stats.idre.ucla.edu/other/mult-pkg/faq/how-do-i-use-a-sas-data-file-in-stata/"
  },
  {
    "objectID": "cheat_sheet/STATACheatSheet.html#get-to-know-your-data",
    "href": "cheat_sheet/STATACheatSheet.html#get-to-know-your-data",
    "title": "Basic Stata Coding Overview",
    "section": "2.3 Get to know your data",
    "text": "2.3 Get to know your data\nOne can get a brief overview of your dataset on the number of observations, the number of variables, variable names, formats, and labels using the describe command. This is highly recommended to do!\ndescribe\nTo see what the entire dataset looks like, one can select on the “Data Browser” icon or use the “browse” command. This will open the data browser that will look a lot like an Excel spreadsheet.\nbrowse\nTo compactly list the variable names:\nds\nTo count the number of observations (i.e. rows of data) in a dataset:\ncount\nTo count the number of observations in a subset of the data:\nCode for character variables:\ncount if varname=='Male'\nCode for numeric variables:\ncount if varname==1\nOne can use the codebook command to print the variable name, label, variable type, range, number of unique values, and some descriptive information. This is very useful for categorical variables. If you do not include a variable name after the codebook command, then you will get output for every variable in the dataset.\ncodebook varname1 varname2 varname3"
  },
  {
    "objectID": "cheat_sheet/STATACheatSheet.html#generate-quadratic-term",
    "href": "cheat_sheet/STATACheatSheet.html#generate-quadratic-term",
    "title": "Basic Stata Coding Overview",
    "section": "3.1 Generate quadratic term",
    "text": "3.1 Generate quadratic term\ngenerate newvar=oldvar*oldvar"
  },
  {
    "objectID": "cheat_sheet/STATACheatSheet.html#generate-a-categorical-variable-based-on-cut-points",
    "href": "cheat_sheet/STATACheatSheet.html#generate-a-categorical-variable-based-on-cut-points",
    "title": "Basic Stata Coding Overview",
    "section": "3.2 Generate a categorical variable based on cut-points",
    "text": "3.2 Generate a categorical variable based on cut-points\nThere are a couple ways to create a categorical variable 'newvar' based on cutpoint values of 'oldvar' at cutpoints x and y.\n\nOne can use the cut function of the egen command to create a new categorical variable with the left-hand ends of the intervals specified in that at() option. For example, say you have a variable with a minimum of 0 and a maximum of 100 with some missing values and you would like to make three categories defined by the values [0,x] (category 1), [x,y] (category 2), and [y,100] (category 3). In the at() option of the egen and cut commands, you will want to supply the left- hand breaks: 0, x, y and then a value larger than the maximum. The label option will label each of the levels of the categorical variable with the left-hand break value. http://www.stata.com/manuals13/degen.pdf\n\n\negen newvar = cut(oldvar), at(0,x,y,101) label\n\nExample:\negen agecat= cut(age), at(0,40,60,80,101) label \n\ntabulate agecat \n\n     agecat |      Freq.     Percent        Cum. \n------------+----------------------------------- \n          0-|        180        2.65        2.65 \n         40-|      2,007       29.51       32.16 \n         60-|      4,271       62.81       94.97 \n         80-|        342        5.03      100.00 \n------------+----------------------------------- \n      Total |      6,800      100.00 \n\n\nUse the generate and replace commands but be aware that Stata will bin those with missing values in the category with an open-ended greatest than sign unless clearly specified. To generate a new categorical variable based on a set of cutpoints (ex. 40, 60, 80):\n\n\ngenerate newvar=0 if oldvar!=. \nreplace newvar=1 if oldvar &gt;= 40 & oldvar &lt; 60 \nreplace newvar=2 if oldvar &gt;=60 & oldvar &lt; 80 \nreplace newvar=3 if oldvar &gt;=80 & oldvar != . \n \n*The syntax '!=' means not equal. This line must be included or else \n*those with missing will be binned in the newvar=3 category \n \ntabulate newvar \n\nAnother way:\ngenerate newvar=0 \nreplace newvar=1 if oldvar &gt;= 40 & oldvar &lt; 60\nreplace newvar=2 if oldvar \n&gt;=60 & oldvar &lt; 80 replace newvar=3 if oldvar &gt;=80 \n replace newvar=. if oldvar==. \n*Without this line, those with missing values will be included\n*in the newvar=3 category \n\ntabulate newvar"
  },
  {
    "objectID": "cheat_sheet/STATACheatSheet.html#generate-quantiles",
    "href": "cheat_sheet/STATACheatSheet.html#generate-quantiles",
    "title": "Basic Stata Coding Overview",
    "section": "3.3 Generate quantiles",
    "text": "3.3 Generate quantiles\nUse the xtile command to generate a categorical variable based on quantiles cutoffs (for tertiles, usenquantile(3); for quartiles, use nquantile(4); etc. the default is nquantile(2)):\nxtile newvar=oldvar, nquantiles(#)"
  },
  {
    "objectID": "cheat_sheet/STATACheatSheet.html#generate-an-indicatordummy-variable",
    "href": "cheat_sheet/STATACheatSheet.html#generate-an-indicatordummy-variable",
    "title": "Basic Stata Coding Overview",
    "section": "3.4 Generate an indicator/dummy variable",
    "text": "3.4 Generate an indicator/dummy variable\n\nTo generate indicator or dummy variables for a categorical variable, one can use the generate() option of the tabulate command, where a stem name is included within the parentheses to generate X number of dummy variables. Stata will use the stem name to create X number of dummy variables starting from stemname1-stemnameX.\n\n\ntabulate newvar, gen(newvar_dummy)  \ntabulate newvar_dummy1 \ntabulate newvar_dummy2  \ntabulate newvar_dummy3  \ntabulate newvar_dummy4  \ntabulate newvar_dummy5 \n\nOne could also code the indicator/dummy variables manually using the generate and replace commands. Again, be aware the Stata will bin those with missing values in a category and you must specify how to handle those with missing.\n\n\ngenerate indicator1 = 0 if oldvar !=. *the syntax '!=' means not equal. \nreplace indicator1=1 if oldvar &lt; 100 & oldvar !=. \n \ngenerate indicator2 = 0 if oldvar !=. \nreplace indicator2=1 if oldvar&gt;=100 & oldvar&lt;200 & oldvar !=. \n \ngenerate indicator3 = 0 if oldvar !=. replace indicator3=1 if  oldvar&gt;=200 &     oldvar !=. \n... \ntabulate indicator1  \ntabulate indicator2 \ntabulate indicator3"
  },
  {
    "objectID": "cheat_sheet/STATACheatSheet.html#label-a-new-variable",
    "href": "cheat_sheet/STATACheatSheet.html#label-a-new-variable",
    "title": "Basic Stata Coding Overview",
    "section": "3.5 Label a new variable",
    "text": "3.5 Label a new variable\nOne can use the label variable command to give a label to a variable:\nlabel variable newvar \"Add your label description here\"\nOne can also add labels to each level of a categorical variable using both the label define and the label values commands. Say we have a variable called newvar that takes on the values 1, 2, 3, 4, and 5 to represent quintiles. We will define each of the levels of newvar and store that information to newvar_f; then, we will assign the values of newvar_f to the variable newvar. We will check that this worked by using the codebook command to see that labels were assigned correctly to the variable and to each level of the categorical variable.\nlabel define newvar_f 1 \"Quintile 1\" 2 \"Quintile 2\" 3 \"Quintile 3\" 4 \"Quintile 4\" 5 \"Quintile 5\"  \n\nlabel values newvar newvar_f \n \ncodebook newvar"
  },
  {
    "objectID": "cheat_sheet/STATACheatSheet.html#sort-the-data",
    "href": "cheat_sheet/STATACheatSheet.html#sort-the-data",
    "title": "Basic Stata Coding Overview",
    "section": "3.6 Sort the data",
    "text": "3.6 Sort the data\nThe default of the sort command is in ascending order.\nsort varname\nYou can sort on multiple variables to arrange observations in to ascending order based on varname1, and within each varname1 category one can sort into ascending order by varname2.\nsort varname1 varname2"
  },
  {
    "objectID": "cheat_sheet/STATACheatSheet.html#merge-two-datasets-with-a-single-row-for-each-individual",
    "href": "cheat_sheet/STATACheatSheet.html#merge-two-datasets-with-a-single-row-for-each-individual",
    "title": "Basic Stata Coding Overview",
    "section": "3.7 Merge two datasets with a single row for each individual",
    "text": "3.7 Merge two datasets with a single row for each individual\nTo merge two datasets, both datasets should be sorted by the identification variable (ex. idvar). After running the merge command line, a variable _merge is created; this can complicate matters if you are merging more than 2 datasets.\nuse \"Yourpathhere/nameofdataset1.dta\", clear sort idvar \nmerge 1:1 idvar using \"Yourpathhere/nameofdataset2.dta\"\nIf both datasets are saved in the same folder location:\ncd \"YourDataLocationFolder/\" use nameofdataset1.dta, clear  sort idvar \nmerge 1:1 idvar using nameofdataset2.dta \nIf you only want to retain observations that appear in both datasets, one can add the keep(match) option to the merge command:\nmerge 1:1 idvar using nameofdataset2.dta, keep(match)"
  },
  {
    "objectID": "cheat_sheet/STATACheatSheet.html#keeping-and-dropping-observations",
    "href": "cheat_sheet/STATACheatSheet.html#keeping-and-dropping-observations",
    "title": "Basic Stata Coding Overview",
    "section": "3.8 Keeping and dropping observations",
    "text": "3.8 Keeping and dropping observations\nPlease note that if you keep or drop certain observations, these observations will not be included in any future data management or analyses.\nkeep if age&gt;35  \nkeep if sex==\"F\"\ndrop if age&lt;=35  drop if sex==\"M\""
  },
  {
    "objectID": "cheat_sheet/STATACheatSheet.html#categorical-data-frequencies-tests-and-association-measures",
    "href": "cheat_sheet/STATACheatSheet.html#categorical-data-frequencies-tests-and-association-measures",
    "title": "Basic Stata Coding Overview",
    "section": "4.1 Categorical data: frequencies, tests, and association measures",
    "text": "4.1 Categorical data: frequencies, tests, and association measures\n\n4.1.1 One-way frequency table\nOne can get a frequency table as well as the percentages and cumulative percentages for categorical data using the tabulate command. To check for those with missing data (i.e. varname==.), one can add the missing option to the tabulate command.\ntabulate varname  tab varname \ntabulate varname, missing\nOne can estimate the proportions, standard errors and 95% CI of the proportions using the proportions command.\nproportion varname1 varname2 varnameX\n\n\n4.1.2 RxC frequency tables\nOne can easily extend the tabulate command to cross-tabulate two categorical variables. There are options in the tabulate command to obtain the Pearson’s Chi-squared statistic and the Fisher’s exact test.\ntabulate varname1 varname2 \ntabulate varname1 varname2, missing \n \ntabulate varname1 varname2, chi2 \ntabulate varname1 varname2, exact \n\n\n4.1.3 Two-sample test of proportions\nNote that the binary variable, varname1, should be coded 0/1.\nprtest varname1, by(varname2)\n\n\n4.1.4 Estimate measures of association\nOne can estimate the Risk Difference, Risk Ratio, Odds Ratio between two binary variables (coded as 0/1) using the cs (i.e. cohort study) command with the or (i.e. Odds Ratio) option.\ncs varname1 varname2, or\n\n\n4.1.5 Stratified frequency tables\nIf you want to see frequencies or summary statistics of a variable (ex. varname1 or varname3) within each value of a categorical variable (ex. categoricalvariable):\nbysort categoricalvariable: tabulate varname1  \nbysort categoricalvariable: summarize varname3 \nAnother way to code:\nsort categoricalvariable \nby categoricalvariable: tabulate varname1 \nby categoricalvariable: summarize varname3 \n \nby categoricalvariable, sort: tabulate varname 1"
  },
  {
    "objectID": "cheat_sheet/STATACheatSheet.html#continuous-data-summary-statistics-visualization-and-statistical-tests",
    "href": "cheat_sheet/STATACheatSheet.html#continuous-data-summary-statistics-visualization-and-statistical-tests",
    "title": "Basic Stata Coding Overview",
    "section": "4.2 Continuous data: summary statistics, visualization, and statistical tests",
    "text": "4.2 Continuous data: summary statistics, visualization, and statistical tests\n\n4.2.1 Measures of location and variance\nUse the summarize command to obtain summary statistics for continuous data (ex. mean, minimum, maximum, standard deviation). The detail option provides additional information on the median, variance, the interquartile range values, and the 4 smallest and 4 largest values.\nsummarize varname  \nsummarize varname, detail \nOne can estimate the standard errors and 95% CI of the mean using the ci or ci means command.\nci means varname1 varname2 varnameX\n\n\n4.2.2 Histogram\nA histogram graphics for continuous data\nhistogram age, frequency xtitle(Age) title(Histogram of age)\n\n\n4.2.3 Box plots\nTo show a box-and-whisker plot of age and a box plot of age by a categorical variable (ex. sex)\ngraph box age, ytitle(Age) title(Box plot of age) \ngraph box age, over(sex) ytitle(Age) title(Box plot of age by sex)\n\n\n4.2.4 Scatterplot\nScatterplot of two continuous variables\ntwoway (scatter age bmi), ytitle(Age) xtitle(BMI)\nMore examples and codes in: http://www.Stata.com/support/faqs/graphics/gph/Stata-graphs/\n\n\n4.2.5 Statistical Tests\nTo conduct a two-sample T-test (normally distributed continuous variable by a binary variable), use the ttest command and select the ‘unequal’ variance option if desired:\nttest continuousvar, by(binaryvar) unequal  \nttest continuousvar, by(binaryvar)\nTo conduct a one-way ANOVA (test differences of two or more means), use the anova or oneway commands:\nanova continuousvar categoricalvar  \noneway continuousvar categoricalvar\nTo conduct a non-parametric test Wilcoxon Rank-sum test (aka Mann-Whitney U test) for non- normally distributed data, use the ranksum command:\nranksum continuousvar, by(categoricalvar)\n\n\n4.2.6 Correlation coefficients\nOne can estimate the Pearson correlation coeffecients using either the correlate or the pwcorr commands, though the output options vary between the two commands. The correlate command has several options including to print out the variable descriptive statistics and if you prefer the covariance matrix, you can use the covariance option. The pwcorr commands has options to output the number of observations for each comparison and the p-values.\ncorrelate varname1 varname2 varname3 varname4, means \ncorrelate varname1 varname2 varname3 varname4, means covariance \npwcorr varname1 varname2 varname3 varname4, obs sig\nOne can estimate the Spearman correlation coefficients using the spearman command. With the stats() option, one can output the Spearman correlation coefficients, number of observations and the p-values.\nspearman varname1 varname2 varname3 varname4, stats(rho obs p)"
  },
  {
    "objectID": "cheat_sheet/STATACheatSheet.html#logistic-regression",
    "href": "cheat_sheet/STATACheatSheet.html#logistic-regression",
    "title": "Basic Stata Coding Overview",
    "section": "5.1 Logistic Regression",
    "text": "5.1 Logistic Regression\n\n5.1.1 Using continuous or binary variables\nCode to output the beta coefficients:\nlogit outcome exposure var1 var2 varx \nlogistic outcome exposure var1 var2 varx, coef\nCode to output the Odds Ratios:\nlogit outcome exposure var1 var2 varx, or  \nlogistic outcome exposure var1 var2 varx\n\n\n5.1.2 Using indicator variables\nTo model the categorical predictors with indicator variables, one can use the ‘i.’ function. The default when you use the ‘i.’ function for indicator variables is that the smallest value is the referent group (i.e. the base level is set to first).\nlogit outcome i.exposure i.var1 var2 varx  \nlogit outcome i.exposure i.var1 var2 varx, or\nTo change the referent group, you can 1) use the fvset command, 2) use the ib#. operator, or 3) manually generate new indicator variables.\n\nUsing the fvset command, you have the option to specify the referent group as the lowest level value (first; the default), the highest level value (last), or the most frequent level value (frequent).\n\n\n\nCode to change the referent group:\n\n\nfvset base [first/last/frequent] var1  \nfvset base first var1 \nfvset base last var1  \nfvset base frequent var1  \nlogistic outcome i.var1\n\nUsing the ib#. operator, you can specify the base level of a factor variable by using the ib. operator.\n\n\n\nFor more information: http://www.Stata.com/manuals13/u11.pdf#u11.4.3.2Baselevels\n\nFor example, if you have a 3-level exposure variable (low, medium, high), the default referent group is ‘low’ and would be the same as using the ib0.varname operator. To have ‘medium’ as the referent group, you can use the ib1.varname operator.\n\nCode to change the referent group using the ib# operator:\n\n\nlogistic outcome ib1.exposure var1 var2 varx, or \n\nYou can also manually code the indicator variables to code the desired referent group.\n\n\nCode to change the referent group manually:\n\n\ngenerate low=0 \nreplace low = 1 if exposure=0  \ngenerate medium=0 \nreplace medium = 1 if exposure=1  \ngenerate high=0 \nreplace high= 1 if exposure=2 \nlogistic outcome low high var1 var2 varx, or\n\n\n5.1.3 Stratified Logistic Regression\nby stratificationvar, sort: logistic outcome exposure"
  },
  {
    "objectID": "cheat_sheet/STATACheatSheet.html#linear-regression",
    "href": "cheat_sheet/STATACheatSheet.html#linear-regression",
    "title": "Basic Stata Coding Overview",
    "section": "5.2 Linear Regression",
    "text": "5.2 Linear Regression\nOne can conduct a linear regression model using the regress command with continuous, binary, categorical and indicator variables (see the Logistic Regression section for more information about using indicator variables).\nregress outcome exposure var1 var2 varx  \nregress outcome exposure var1 var2 varx"
  },
  {
    "objectID": "cheat_sheet/STATACheatSheet.html#survival-data",
    "href": "cheat_sheet/STATACheatSheet.html#survival-data",
    "title": "Basic Stata Coding Overview",
    "section": "5.3 Survival Data",
    "text": "5.3 Survival Data\n\n5.3.1 Set-up\nTell Stata that the dataset is survival data:\nstset timetooutcome, failure(outcome==1) \n\n\n5.3.2 Graphs\nKM Curves Overall:\nsts graph \nKM Curves by exposure groups:\nsts graph, by(exposure) \nTo add 95% Confidence Interval band and information sample sizes to the figure\nsts graph, by(exposure) ci risktable \nLog negative-log survivor plots\nstphplot, by(exposure)\n\n\n5.3.3 Summary statistics\nTo see survivor function at various time points overall and by groups:\nsts list \nsts list, by(exposure) compare \nTo get median and other percentile survival times with confidence intervals:\nstci, by(exposure) median  \nstci, by(exposure) p(25)  \nstci, by(exposure) p(75)  \nstsum, by(exposure)\n\n\n5.3.4 Statistical tests\nLog-Rank Test\nsts test exposure, logrank \nWeighted Log-Rank tests (Wilcoxon, Tarone-Ware):\nsts test exposure, wilcoxon  \nsts test exposure, tware\n\n\n5.3.5 Cox Regression\nOne can conduct a Cox regression model using the stcox command to estimate Hazard Ratios with continuous, binary, categorical and indicator variables (see the Logistic Regression section for more information about using indicator variables). In order for the stcox command to work, you must tell Stata that you are working with survival data by using the stset command. The option ‘nohr’ will output the beta coefficients, not the Hazard Ratios.\nstset timetooutcome, failure(outcome==1)  stcox i.var1 var2 var3 \nstcox i.var1 var2 var3, nohr\nCox Regression with time-varying covariates:\nstcox i.var1 var2 var3, tvc(i.var1) texp(_t) nohr\nCompeting Risk Analysis: In carrying out a competing risk analysis, the “outcome” variable can take on three values. There must be a value for the actual event of interest (outcome=1); a value for censoring (outcome=0); and a value for the competing risk event (outcome=2). The stset command needs to be given first, in the usual way to identify the event of interest.\nCumulative Incidence Curve (you must run the Cox regression first with at least one predictor)\nstcrreg var1, compete(outcome==2) stcurve, cif\nCox Regression with a Competing Risk\nstcrreg i.var1 var2 var3, compete(outcome==2)"
  },
  {
    "objectID": "cheat_sheet/STATACheatSheet.html#goodness-of-fit-statistics",
    "href": "cheat_sheet/STATACheatSheet.html#goodness-of-fit-statistics",
    "title": "Basic Stata Coding Overview",
    "section": "5.4 Goodness of Fit Statistics",
    "text": "5.4 Goodness of Fit Statistics\nTo get log Likelihood/AIC/BIC for most recent regression model:\nestat ic \nTo run Likelihood Ratio Test comparing two nested models:\nlogit outcome exposure var1  estimates store nicknameformodel1 \n \nlogit outcome exposure var1 var2  estimates store nicknameformodel2 \n \nlrtest nicknameformodel2 nicknameformodel1 lrtest nicknameformodel2 nicknameformodel1, stats"
  },
  {
    "objectID": "cheat_sheet/STATACheatSheet.html#creating-table-1-in-stata",
    "href": "cheat_sheet/STATACheatSheet.html#creating-table-1-in-stata",
    "title": "Basic Stata Coding Overview",
    "section": "6.1 Creating table 1 in stata",
    "text": "6.1 Creating table 1 in stata\nThese packages may be useful to you for creating a Table 1 in Stata (showing summary/descriptive statistics.). They are very helpful for your group project and data presentation for publication\n\nMake a Table 1 in Stata in no time with “table1_mc” package\n\nhttps://blog.uvm.edu/tbplante/2019/07/11/make-a-table-1-in-stata-in-no-time-with-table1_mc/\n\nMake a Table 1 in Stata with “basetable” package\n\nhttp://www.bruunisejs.dk/StataHacks/basetable/basetable_demo/"
  },
  {
    "objectID": "cheat_sheet/STATACheatSheet.html#table-of-links-to-helpful-manuals-and-youtube-videos",
    "href": "cheat_sheet/STATACheatSheet.html#table-of-links-to-helpful-manuals-and-youtube-videos",
    "title": "Basic Stata Coding Overview",
    "section": "6.2 Table of links to helpful manuals and YouTube videos",
    "text": "6.2 Table of links to helpful manuals and YouTube videos\n\n\n\n\nStata Manual\nHelpful YouTube Videos\n\n\n\n\nGetting Started with Stata\n\n6 very nice, short and helpful EdX videos for Stata beginners: https://www.youtube.com/playlist?list=PL6p7gIm6aWd-Y1htnfC9QN57fACk8PiCo\n\n\n.do files\nhttp://www.stata.com/manuals13/u16.pdf\nhttps://www.youtube.com/watch?v=6syxC5jJz-s\n\n\nReading in datasets\nhttp://www.stata.com/manuals13/u21.pdf\nhttps://www.youtube.com/watch?v=3CjXMC2hFEA\n\n\nBasic Data Management\nCreating new variables: http://www.stata.com/manuals13/gsw11.pdf\nCreating new variables and labels: https://www.youtube.com/watch?v=geN1eI64rQU&list=PL6p7gIm6aWd-Y1htnfC9QN57fACk8PiCo&index=5\n\n\n\negen - Extensions to generate: http://www.stata.com/manuals13/degen.pdf\nGenerating variables using the generate, replace, and label commands: https://www.youtube.com/watch?v=WX5vbQgfkSc\n\n\n\npctile - Create variable containing percentiles: http://www.stata.com/manuals13/dpc tile.pdf\n\n\n\n\nHow do I create dummy variables?: https://www.stata.com/support/faqs/data-management/creating-dummyvariables/\n\n\n\n\nmerge - Merge datasets: http://www.stata.com/manuals13/dmerge.pdf\n\n\n\nDescriptives, basic graphs\n\nExploratory data analysis: https://www.youtube.com/watch?v=zt8eX9xcbCo&t=2s&list=PL6p7gIm6aWd-Y1htnfC9QN57fACk8PiCo&index=4\n\n\n\n\nGraphing in stata: https://www.youtube.com/watch?v=dnnUOCVjF8s&list=PL6p7gIm6aWd-Y1htnfC9QN57fACk8PiCo&index=6\n\n\n\n\nSTATA The Very Basics: https://www.youtube.com/watch?v=kepM_tbQokw"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Introduction to R",
    "section": "",
    "text": "June 6-9, 2023\n\n2-5 pm\n\n\nFaculty\nLouisa Smith\nAssistant Professor\nDepartment of Health Sciences, Northeastern University\nl.smith@northeastern.edu\nOffice Hours: 1-2 pm Kresge 201\n\nTeaching Assistant\nSabine Friedrich\nsfriedrich@hsph.harvard.edu\nOffice hours: 12-1 pm Kresge 201"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "pre_work/index.html",
    "href": "pre_work/index.html",
    "title": "Pre-work",
    "section": "",
    "text": "Install R and RStudio\n\nDownload R from CRAN. Choose the link at the top that corresponds to your operating system.  Unless you downloaded R within the past month or two, do so again – you want the most up-to-date version (≥ R 4.3) for this class.\nDownload RStudio (step 2 on that page – you already completed step 1 above!). It should automatically recognize your operating system, but if not, choose the correct link at the bottom.\n\nIf you have a Mac, make sure you choose correctly between the Apple Silicon (M1/M2) and Intel options.Which version of RStudio you have is not as important, but it’s nice to stay up-to-date for the newest features!\n\nReadings\n\nSections 1.4-1.5 of R for Data Science. Run the code in your RStudio console as you go.\nChapter 3 of R for Data Science. Again, run the code in your RStudio console as you read. Try the exercises.\nOptional, but helpful: Chapter 2 of Hands-On Programming with R. For the purposes of this class, we will necessarily skip some of the R basics to focus on the skills you’ll need most. This is a good resource if you want to learn more about them, so it’s highly recommended, you just don’t need to master it as part of your pre-work.\n\nIn particular, make sure you install the packages in the text.If you’re wondering what happened to chapter 2, we’ll be doing that one together!\n\nHomework"
  },
  {
    "objectID": "resources.html",
    "href": "resources.html",
    "title": "Resources",
    "section": "",
    "text": "R for Data Science Slack learning group: https://www.rfordatasci.com/about/\nMore extensive Harvard course covering R and other aspects of computing: https://id529.github.io/\nRMarkdown book: https://bookdown.org/yihui/rmarkdown/\nQuarto: https://quarto.org/\nInstalling LateX to generate PDFs with RMarkdown or Quarto: https://bookdown.org/yihui/rmarkdown-cookbook/install-latex.html\nCheat sheets: https://posit.co/resources/cheatsheets/"
  }
]